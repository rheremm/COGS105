{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 Model Fitting with Maximum Likelihood \n",
    "* The purpose of this assignment is to learn how to write a log likelihood function, fit models to data with maximum likelihood and to select among models using AIC and a validation set.  \n",
    "* Along the way, we'll learn a bit about decision making models and response time data.  \n",
    "\n",
    "### Due: Sunday 10/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Perceptual Discrimination Task to Study Decision Making\n",
    "\n",
    "This is actual data from my lab, which was published here:\n",
    "\n",
    "Nunez, M. D., Vandekerckhove, J., & Srinivasan, R. (2017). How attention influences perceptual decision making: Single-trial EEG correlates of drift-diffusion model parameters. Journal of Mathematical Psychology, 76(Part B), 117â€“130. https://doi.org/10.1016/j.jmp.2016.03.003\n",
    "\n",
    "Human subject were asked to discriminate the spatial frequency of Gabor patches (as shown below), embeded in noise.  Task difficulty was controlled by the difficulty of the discrimination.  Two Gabors with more similar spatial frequencies are harder to discriminate, especially when noise is added.  In each of 34 participant, The experiment was performed in Easy, Medium, and Hard blocks each consisting of with decreasing differences between the Gabor spatial frequencies.  \n",
    "\n",
    "![](spatialfrequency.png)\n",
    "\n",
    "The datafile ReactionTimeData.csv is for use in this homework. You can load it into your notebook using pandas using pandas. There are 3 variables in the file: \n",
    "\n",
    "* Subject - indicates a numeric subject id \n",
    "* Experimental Condition - Easy, Medium, Hard \n",
    "* Correct - 1 if correct 0 if incorrect \n",
    "* ResponseTime  - time from stimulus presentation to decision in units of millisecond "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ResponseTimeData.csv')\n",
    "rt = np.array(df['ResponseTime'])\n",
    "correct = np.array(df['Correct'])\n",
    "condition = np.array(df['Condition'])\n",
    "condition_labels = ['Easy','Medium','Hard']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1 Explore and Visualize the Data.  I recommend using this exercise to learn about seaborn. \n",
    "a. make a histogram of Response Time showing all 3 difficulty conditions in a single graph.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. make a bar graph showing the accuracy (proportion or percentage correct) in each condition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Make a boxplot that shows the distributions of each condition, with correct and incorrect trials separated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Calculate the mean reaction time for each subject in each condition.  Make a histogram that shows the distribution of mean RT across subjects,showing all 3 conditions in a single graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we discussed how different distributions might be used to model Response Time data in decision making tasks.  In particular, the shifted Wald distribution is a distribution that captures aspects of the processes that give rise to Response Time.  \n",
    "\n",
    "The shifted Wald distribution is a 1-boundary model. And, for simplicity, we will only consider correct trials.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftedwald(params, x):\n",
    "    '''\n",
    "    params: is a list or numpy array containing two parameters\n",
    "    x: are the data\n",
    "    '''\n",
    " \n",
    "    gamma = params[0] #drift rate\n",
    "    alpha = params[1] #boundary separation\n",
    "    theta = params[2] #shift or nondecision time \n",
    "    x = x-theta\n",
    "    z = alpha/np.sqrt(2*np.pi*(x**3))\n",
    "    w = ((np.abs(alpha-gamma*x))**2)/(2*x)\n",
    "    f = z*np.exp(-w)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 \n",
    "Use the shifted Wald distribution defined above.  Write a function which computes the negative log likelihood of the shifted Wald distribution.  Assume that the data to be analyzed is in a variable called data. \n",
    "\n",
    "The function should return negative log likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negloglikeWald(params):\n",
    "    ''' written with params containing gamma, alpha, theta in that order.  Assumes data is in the variable data'''\n",
    "    cprob = shiftedwald(params,data)\n",
    "    cprob = np.maximum(cprob,1e-10) #to avoid log(0)\n",
    "    negloglike = -np.sum(np.log(cprob))\n",
    "    return negloglike "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 \n",
    "\n",
    "Using the function the negative log-likelihood that you developed in problem 1, fit the shifted Wald distribution to the data for ALL the subjects in ReactionTimeData.csv.  \n",
    "\n",
    "You should consider two models: \n",
    "Model A: All of the data comes from a single distribution. \n",
    "Model B: The data in each condition (Easy, Medium, Hard) comes from a separate distribution. \n",
    "\n",
    "When providing bounds to the fitting process, keep in mind that the only constraints on the parameters of this model is that they have to be positive.  To specify an upper bound of infinity, use `np.inf`\n",
    "\n",
    "If you run into problems with your computer taking too long, reduce the amount of data, even do just 1 or a few subjects.\n",
    "\n",
    "Make a plot or table or something to show me (make it pretty!) how the resulting parameter fits turned out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfit = dict()\n",
    "data = rt[(correct == 1)]  #only use correct response \n",
    "bnds = ((0.01, np.inf), (0.01, np.inf), (0.01, np.min(data)-1))\n",
    "paramfit['All'] = minimize(negloglikeWald, [0.1,100,200], bounds = bnds, options={'maxfun': 100000})\n",
    "for c in condition_labels:\n",
    "    data = rt[(correct == 1) & (condition == c)] \n",
    "    paramfit[c] = minimize(negloglikeWald, [0.1,100,200], bounds = bnds, options={'maxfun': 100000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  message: CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 62486.859278231204\n",
      "        x: [ 9.916e-02  6.493e+01  1.905e+02]\n",
      "      nit: 21\n",
      "      jac: [-1.150e-01 -9.459e-03  3.201e-02]\n",
      "     nfev: 96\n",
      "     njev: 24\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "print(paramfit['All'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 \n",
    "\n",
    "Use AIC to evaluate which model you should prefer.  Do the data come from 1 distribution or from three different distributions?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': np.float64(124979.71855646241), 'B': np.float64(124689.52488065843)}\n"
     ]
    }
   ],
   "source": [
    "aic = dict()\n",
    "# for one model k = 3\n",
    "k = 3\n",
    "aic['A'] = 2*k + 2*paramfit['All']['fun']\n",
    "# for 3 models k = 9 \n",
    "k = 9\n",
    "aic['B'] = 2*k + 2*(paramfit['Easy']['fun'] + paramfit['Medium']['fun'] + paramfit['Hard']['fun'])\n",
    "print(aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 \n",
    "\n",
    "The two models given above are not the only models we could propose. The power of likelihood and modeling (as opposed to statistical testing) is if we can be very specific about our hypothesis.    \n",
    "\n",
    "The original idea of this experiment was to manipulate drift rate in order to find brain activity related to speed of information processing. \n",
    "So, our hypothesis was that non-decision time, and boundary would be the same for all conditions, and only the drift rate would vary.  \n",
    "\n",
    "Write a function for negative log likelihood for a model that keeps boundary (alpha) and non-decision time (theta) the same for all 3 conditions, but allows drift rate (gamma) to vary between conditions. \n",
    "\n",
    "In this model there are now 5 parameters - gamma_easy, gamma_medium, gamma_hard, alpha, theta. \n",
    "The likelihood should be evaluated using the correct gamma for each condition, and using the sama alpha and theta for all condition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negloglikeWald_C(params):\n",
    "    ''' written with params containing gamma_easy, gamma_medium, gamma_hard, alpha, theta in that order.  Assumes data is in the variable data'''\n",
    "    cprob = dict()\n",
    "    negloglike = 0\n",
    "    for i,c in enumerate(condition_labels):\n",
    "        data_i = data[(accuracy == 1) & (clabel == c)] \n",
    "        params_i = [params[i], params[3], params[4]] # gamma for condition i, alpha, theta\n",
    "        cprob = shiftedwald(params_i,data_i)\n",
    "        cprob = np.maximum(cprob,1e-10) #to avoid log(0)\n",
    "        negloglike = negloglike-np.sum(np.log(cprob))\n",
    "    return negloglike "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "Use you new likelihood you developed in Problem 5 to fit the data (call it model C), and compare to models A and B using AIC. Make a new table showing the parameters for each model and which model seems to fit the data the best. (by AIC)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rt  #use all response \n",
    "accuracy = correct\n",
    "clabel = condition\n",
    "bnds = ((0.01, np.inf), (0.01, np.inf), (0.01, np.inf), (0.01, np.inf), (0.01, np.min(data)-1))\n",
    "paramfit['Optimal'] = minimize(negloglikeWald_C, [0.1,0.1,0.1,100,200], bounds = bnds, options={'maxfun': 100000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  message: CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 62339.34035566585\n",
      "        x: [ 1.094e-01  1.002e-01  9.192e-02  6.595e+01  1.907e+02]\n",
      "      nit: 23\n",
      "      jac: [-1.019e-02  1.819e-02  2.183e-03 -3.711e-02  1.361e-01]\n",
      "     nfev: 162\n",
      "     njev: 27\n",
      " hess_inv: <5x5 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "print(paramfit['Optimal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': np.float64(124979.71855646241), 'B': np.float64(124689.52488065843), 'C': np.float64(124688.6807113317)}\n"
     ]
    }
   ],
   "source": [
    "aic['C'] = 2*5 + 2*paramfit['Optimal']['fun']  #k = 5\n",
    "print(aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7 (Experimental) - not required.  \n",
    "\n",
    "Use sklearn's test_train_split to split the dataframe you read from ResponseTime.csv into training and test dataframes.  Keep around 0.2 or 0.3 of the data for testing.  When you do this, remember to stratify by participant!  Fit models A,B,C to the training data.  Then choose the best parameter values for each model to compute the likelihood of each model and identify which model has maximum likelihood in the test data. No AIC needed!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Subject', 'Condition', 'Correct', 'ResponseTime'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# key here is that I used the stratify option to ensure that the train and test sets have similar distribution of subjects  \n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify = df['Subject'],random_state=42)\n",
    "#grab the data from the training set\n",
    "rt_train = np.array(df_train['ResponseTime'])\n",
    "correct_train = np.array(df_train['Correct'])\n",
    "condition_train = np.array(df_train['Condition'])\n",
    "#grab the data from the test set\n",
    "rt_test = np.array(df_test['ResponseTime'])\n",
    "correct_test = np.array(df_test['Correct'])\n",
    "condition_test = np.array(df_test['Condition'])\n",
    "#make labels\n",
    "condition_labels = ['Easy','Medium','Hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Subject",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b8818c4d-2400-4c29-9993-dd56b61f06e1",
       "rows": [
        [
         "22",
         "284"
        ],
        [
         "32",
         "284"
        ],
        [
         "16",
         "284"
        ],
        [
         "9",
         "284"
        ],
        [
         "8",
         "284"
        ],
        [
         "10",
         "283"
        ],
        [
         "4",
         "282"
        ],
        [
         "3",
         "282"
        ],
        [
         "27",
         "282"
        ],
        [
         "17",
         "282"
        ],
        [
         "28",
         "282"
        ],
        [
         "23",
         "282"
        ],
        [
         "15",
         "281"
        ],
        [
         "6",
         "281"
        ],
        [
         "31",
         "280"
        ],
        [
         "13",
         "280"
        ],
        [
         "11",
         "278"
        ],
        [
         "18",
         "277"
        ],
        [
         "24",
         "276"
        ],
        [
         "19",
         "276"
        ],
        [
         "7",
         "275"
        ],
        [
         "20",
         "275"
        ],
        [
         "26",
         "274"
        ],
        [
         "25",
         "274"
        ],
        [
         "5",
         "272"
        ],
        [
         "30",
         "272"
        ],
        [
         "34",
         "270"
        ],
        [
         "29",
         "270"
        ],
        [
         "12",
         "269"
        ],
        [
         "2",
         "266"
        ],
        [
         "33",
         "263"
        ],
        [
         "14",
         "254"
        ],
        [
         "21",
         "246"
        ],
        [
         "1",
         "163"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 34
       }
      },
      "text/plain": [
       "Subject\n",
       "22    284\n",
       "32    284\n",
       "16    284\n",
       "9     284\n",
       "8     284\n",
       "10    283\n",
       "4     282\n",
       "3     282\n",
       "27    282\n",
       "17    282\n",
       "28    282\n",
       "23    282\n",
       "15    281\n",
       "6     281\n",
       "31    280\n",
       "13    280\n",
       "11    278\n",
       "18    277\n",
       "24    276\n",
       "19    276\n",
       "7     275\n",
       "20    275\n",
       "26    274\n",
       "25    274\n",
       "5     272\n",
       "30    272\n",
       "34    270\n",
       "29    270\n",
       "12    269\n",
       "2     266\n",
       "33    263\n",
       "14    254\n",
       "21    246\n",
       "1     163\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Subject",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d8d0a54c-0763-4d20-a9e6-268e4365fb5c",
       "rows": [
        [
         "22",
         "71"
        ],
        [
         "15",
         "71"
        ],
        [
         "16",
         "71"
        ],
        [
         "10",
         "71"
        ],
        [
         "32",
         "71"
        ],
        [
         "9",
         "71"
        ],
        [
         "4",
         "71"
        ],
        [
         "8",
         "71"
        ],
        [
         "17",
         "70"
        ],
        [
         "23",
         "70"
        ],
        [
         "31",
         "70"
        ],
        [
         "3",
         "70"
        ],
        [
         "6",
         "70"
        ],
        [
         "28",
         "70"
        ],
        [
         "13",
         "70"
        ],
        [
         "27",
         "70"
        ],
        [
         "11",
         "70"
        ],
        [
         "25",
         "69"
        ],
        [
         "18",
         "69"
        ],
        [
         "24",
         "69"
        ],
        [
         "7",
         "69"
        ],
        [
         "19",
         "69"
        ],
        [
         "20",
         "69"
        ],
        [
         "29",
         "68"
        ],
        [
         "34",
         "68"
        ],
        [
         "5",
         "68"
        ],
        [
         "26",
         "68"
        ],
        [
         "30",
         "68"
        ],
        [
         "12",
         "67"
        ],
        [
         "33",
         "66"
        ],
        [
         "2",
         "66"
        ],
        [
         "14",
         "63"
        ],
        [
         "21",
         "62"
        ],
        [
         "1",
         "41"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 34
       }
      },
      "text/plain": [
       "Subject\n",
       "22    71\n",
       "15    71\n",
       "16    71\n",
       "10    71\n",
       "32    71\n",
       "9     71\n",
       "4     71\n",
       "8     71\n",
       "17    70\n",
       "23    70\n",
       "31    70\n",
       "3     70\n",
       "6     70\n",
       "28    70\n",
       "13    70\n",
       "27    70\n",
       "11    70\n",
       "25    69\n",
       "18    69\n",
       "24    69\n",
       "7     69\n",
       "19    69\n",
       "20    69\n",
       "29    68\n",
       "34    68\n",
       "5     68\n",
       "26    68\n",
       "30    68\n",
       "12    67\n",
       "33    66\n",
       "2     66\n",
       "14    63\n",
       "21    62\n",
       "1     41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfit_train = dict()\n",
    "data = rt_train[(correct_train == 1)]  #only use correct response \n",
    "bnds = ((0.01, np.inf), (0.01, np.inf), (0.01, np.min(data)-1))\n",
    "paramfit_train['All'] = minimize(negloglikeWald, [0.1,100,200], bounds = bnds, options={'maxfun': 100000})\n",
    "for c in condition_labels:\n",
    "    data = rt_train[(correct_train == 1) & (condition_train == c)] \n",
    "    paramfit_train[c] = minimize(negloglikeWald, [0.1,100,200], bounds = bnds, options={'maxfun': 100000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters for all data: gamma, alpha, theta\n",
      "[9.91617866e-02 6.49312830e+01 1.90482827e+02]\n",
      "Fitted parameters for training data: gamma, alpha, theta\n",
      "[9.87862566e-02 6.48076208e+01 1.90494342e+02]\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitted parameters for all data: gamma, alpha, theta\")\n",
    "print(paramfit['All']['x'])\n",
    "print(\"Fitted parameters for training data: gamma, alpha, theta\")\n",
    "print(paramfit_train['All']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters for Easy data: gamma, alpha, theta\n",
      "[1.07165862e-01 6.46756428e+01 1.89931822e+02]\n",
      "Fitted parameters for Easy training data: gamma, alpha, theta\n",
      "[1.07373273e-01 6.47552958e+01 1.89994944e+02]\n",
      "Fitted parameters for Medium data: gamma, alpha, theta\n",
      "[1.00306572e-01 6.60113518e+01 1.90609900e+02]\n",
      "Fitted parameters for Medium training data: gamma, alpha, theta\n",
      "[1.00033752e-01 6.60329877e+01 1.90661473e+02]\n",
      "Fitted parameters for Hard data: gamma, alpha, theta\n",
      "[9.44810595e-02 6.76911617e+01 1.91756188e+02]\n",
      "Fitted parameters for Hard training data: gamma, alpha, theta\n",
      "[9.35386547e-02 6.71912874e+01 1.91622777e+02]\n"
     ]
    }
   ],
   "source": [
    "for c in condition_labels:\n",
    "    print(f\"Fitted parameters for {c} data: gamma, alpha, theta\")\n",
    "    print(paramfit[c]['x'])\n",
    "    print(f\"Fitted parameters for {c} training data: gamma, alpha, theta\")\n",
    "    print(paramfit_train[c]['x'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rt_train  #use all response\n",
    "accuracy = correct_train\n",
    "clabel = condition_train\n",
    "bnds = ((0.01, np.inf), (0.01, np.inf), (0.01, np.inf), (0.01, np.inf), (0.01, np.min(data)-1))\n",
    "paramfit_train['Optimal'] = minimize(negloglikeWald_C, [0.1,0.1,0.1,100,200], bounds = bnds, options={'maxfun': 100000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters for all data, Optimal model: gamma_easy, gamma_medium,gamma_hard, alpha, theta\n",
      "[1.09417357e-01 1.00229615e-01 9.19174624e-02 6.59546394e+01\n",
      " 1.90658494e+02]\n",
      "Fitted parameters for training data, Optimal model: gamma_easy, gamma_medium,gamma_hard, alpha, theta\n",
      "[1.09333783e-01 9.97831006e-02 9.15713422e-02 6.58642253e+01\n",
      " 1.90670286e+02]\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitted parameters for all data, Optimal model: gamma_easy, gamma_medium,gamma_hard, alpha, theta\")\n",
    "print(paramfit['Optimal']['x'])\n",
    "print(\"Fitted parameters for training data, Optimal model: gamma_easy, gamma_medium,gamma_hard, alpha, theta\")\n",
    "print(paramfit_train['Optimal']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Likelihood_test = dict()\n",
    "data = rt_test[(correct_test == 1)]  #only use correct response\n",
    "Likelihood_test['A'] = negloglikeWald(paramfit_train['All']['x'])\n",
    "data = rt_test\n",
    "accuracy = correct_test\n",
    "clabel = condition_test\n",
    "Likelihood_test['C'] = negloglikeWald_C(paramfit_train['Optimal']['x'])\n",
    "Likelihood_test['B'] = 0                                 \n",
    "for c in condition_labels:\n",
    "    data = rt_test[(correct_test == 1) & (condition_test == c)]\n",
    "    Likelihood_test['B'] = Likelihood_test['B'] + negloglikeWald(paramfit_train[c]['x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': np.float64(12446.58906683985), 'C': np.float64(12421.126925877485), 'B': np.float64(12419.595278913697)}\n"
     ]
    }
   ],
   "source": [
    "print(Likelihood_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
